{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T10:26:15.348000Z",
     "start_time": "2018-12-27T10:26:13.153583Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#This code is for adaptive GPU usage\n",
    "import keras.backend as K\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T10:26:16.212784Z",
     "start_time": "2018-12-27T10:26:15.962557Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dense, Input\n",
    "from keras.models import Model\n",
    "import keras.optimizers as O\n",
    "import keras.losses as L\n",
    "import keras.activations as A\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from numpy.random import seed\n",
    "\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T10:26:16.589293Z",
     "start_time": "2018-12-27T10:26:16.580639Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(num_timesteps = 50, num_input = 9, num_hidden = 128, num_classes = 3):\n",
    "    '''\n",
    "        Function that builds and returns a basline LSTM model.\n",
    "        Architecture : \n",
    "        Layer 1 : Input Layer.\n",
    "        Layer 2 : LSTM Layer.\n",
    "        Layer 3 : Dense layer with num_classes number of nodes.\n",
    "        \n",
    "        I/P:\n",
    "            num_timesteps : no. of timesteps that are present in the dataset.\n",
    "            num_input : no. of input signals for the Input layer.\n",
    "            num_hidden : no. of hidden units for the LSTM layer.\n",
    "            num_classes : no. of output classes, for the dense layer.\n",
    "            \n",
    "        Returns : \n",
    "            Constructed model.\n",
    "    '''\n",
    "    ip = Input(shape = (num_timesteps, num_input))\n",
    "    x_ip = LSTM(num_hidden)(ip)\n",
    "    x_op = Dense(num_classes, activation='softmax')(x_ip)\n",
    "    \n",
    "    model = Model(inputs = [ip], outputs = [x_op])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer = O.Adam(), loss = L.categorical_crossentropy, metrics = ['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T10:26:17.327242Z",
     "start_time": "2018-12-27T10:26:17.320671Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(path = '/home/iot/Documents/dataset_fog_release/dataset/RAW/'):\n",
    "    '''\n",
    "        Function that takes in the path of a dataset and reads and returns the train, validation and test\n",
    "        splits.\n",
    "    '''\n",
    "    x_train, y_train = np.load(path + 'x_train.npy'), np.load(path + 'y_train.npy')\n",
    "    x_test, y_test = np.load(path + 'x_test.npy'), np.load(path + 'y_test.npy')\n",
    "    x_val, y_val = np.load(path + 'x_val.npy'), np.load(path + 'y_val.npy')\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T09:26:09.654778Z",
     "start_time": "2018-12-27T09:19:47.750590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 50, 9)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               70656     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 71,043\n",
      "Trainable params: 71,043\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 526 samples, validate on 59 samples\n",
      "Epoch 1/10\n",
      "526/526 [==============================] - 1s 2ms/step - loss: 0.9179 - acc: 0.6255 - val_loss: 0.5936 - val_acc: 0.6780\n",
      "Epoch 2/10\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 0.5657 - acc: 0.7510 - val_loss: 0.4538 - val_acc: 0.6949\n",
      "Epoch 3/10\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 0.4355 - acc: 0.8175 - val_loss: 0.3929 - val_acc: 0.8475\n",
      "Epoch 4/10\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 0.3488 - acc: 0.8631 - val_loss: 0.3572 - val_acc: 0.8305\n",
      "Epoch 5/10\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 0.3387 - acc: 0.8726 - val_loss: 0.2879 - val_acc: 0.8983\n",
      "Epoch 6/10\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 0.3343 - acc: 0.8612 - val_loss: 0.2733 - val_acc: 0.8983\n",
      "Epoch 7/10\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 0.2968 - acc: 0.8726 - val_loss: 0.1883 - val_acc: 0.9322\n",
      "Epoch 8/10\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 0.2784 - acc: 0.8897 - val_loss: 0.2600 - val_acc: 0.8983\n",
      "Epoch 9/10\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 0.2700 - acc: 0.8878 - val_loss: 0.3555 - val_acc: 0.9153\n",
      "Epoch 10/10\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 0.2692 - acc: 0.8916 - val_loss: 0.2219 - val_acc: 0.9322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc5e06bb6a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/home/iot/Documents/dataset_fog_release/dataset/RAW/\"\n",
    "x_train, y_train, x_test, y_test, x_val, y_val = load_data(path)\n",
    "\n",
    "model = build_model(num_timesteps = x_train.shape[1], num_input = x_train.shape[-1], num_hidden = 128, num_classes = y_train.shape[-1])\n",
    "\n",
    "model.fit(x_train,y_train,epochs=10,batch_size=32,validation_data=[x_val,y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T09:26:09.654778Z",
     "start_time": "2018-12-27T09:19:47.750590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25051188468933105\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "preds = model1.predict(x_test,batch_size=32)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "#200ms vs #80ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T09:26:09.654778Z",
     "start_time": "2018-12-27T09:19:47.750590Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Convert the predictions into one-hot outputs.\n",
    "preds = np_utils.to_categorical(np.argmax(preds,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T09:26:09.668370Z",
     "start_time": "2018-12-27T09:26:09.657949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Classification Accuracy :  0.8333333333333334\n",
      "CPU times: user 1.47 ms, sys: 3.17 ms, total: 4.64 ms\n",
      "Wall time: 11.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print (\"Final Classification Accuracy : \",accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ea7c303ee66c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'baseline_lstm.h5'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# creates a HDF5 file 'my_model.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m  \u001b[0;31m# deletes the existing model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('baseline_lstm.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model\n",
    "\n",
    "    # returns a compiled model\n",
    "    # identical to the previous one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('baseline_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
